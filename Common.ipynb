{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgYdY0rUerwu"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53911,
     "status": "ok",
     "timestamp": 1681039499925,
     "user": {
      "displayName": "Назарян Марат Гарникович",
      "userId": "18443528347126523641"
     },
     "user_tz": -180
    },
    "id": "lrd2CixBbopP",
    "outputId": "c3b350e2-a269-42a4-95d0-0397608f21a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification import BinaryRecall\n",
    "from torchmetrics.classification import BinarySpecificity\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from torchmetrics.classification import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Af7XqVcekW"
   },
   "source": [
    " # DataSet & DataLoader preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bo5QcMZjM4hp"
   },
   "outputs": [],
   "source": [
    "class DatasetPTBXL(Dataset):\n",
    "\n",
    "    def __init__(self, path,p_list,p_name):\n",
    "        self.path = path\n",
    "        self.len = len(os.listdir(self.path))\n",
    "        self.target_list = p_list\n",
    "        self.target_name = p_name\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = np.load(path + str(idx) + '.npy', allow_pickle=True).item()\n",
    "        return torch.from_numpy(file['data']), torch.from_numpy(file['target'][ptlg_list.index(ptlg_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/narmarinad_12/Desktop/ECG/files_processed/'\n",
    "ptlg_list = ['SR', 'AFIB', 'STACH', 'SARRH', 'SBRAD', 'PACE', 'SVARR', 'BIGU', 'AFLT', 'SVTAC', 'PSVT', 'TRIGU']\n",
    "ptlg_name = 'SR'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93919,
     "status": "ok",
     "timestamp": 1681039745166,
     "user": {
      "displayName": "Назарян Марат Гарникович",
      "userId": "18443528347126523641"
     },
     "user_tz": -180
    },
    "id": "QqE4ncf0x-SY",
    "outputId": "4fcf7450-2c46-4bf6-b405-f3d64da14702"
   },
   "outputs": [],
   "source": [
    "train_dataset = DatasetPTBXL(path,ptlg_list,ptlg_name)\n",
    "\n",
    "tmp_len = len(train_dataset)\n",
    "train_size = int (0.8 * tmp_len) \n",
    "valid_size = int (0.1 * tmp_len)\n",
    "test_size = tmp_len - train_size - valid_size\n",
    "\n",
    "train_dataset, valid_dataset,test_dataset = random_split(train_dataset, [train_size, valid_size, test_size])                                                                       \n",
    "batch_size = 500\n",
    "train_dataset = DataLoader(train_dataset, batch_size, num_workers = 5, pin_memory = True ) \n",
    "valid_dataset = DataLoader(valid_dataset, batch_size, num_workers = 5, pin_memory = True )\n",
    "test_dataset  = DataLoader(test_dataset , batch_size, num_workers = 5, pin_memory = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uu8Y928Rf3A"
   },
   "source": [
    "# Model\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSi9xCepUm1X"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, identity_downsample = None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.resblock = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "                      nn.BatchNorm1d(out_channels),\n",
    "                      nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                      nn.BatchNorm1d(out_channels))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.resblock(x)\n",
    "        #in case we need to double size of identity\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWShc0EwYxYj"
   },
   "outputs": [],
   "source": [
    "#ResNet34\n",
    "class RhythmECGClassification(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, num_classes,class_index,device):\n",
    "        \n",
    "        super(RhythmECGClassification, self).__init__()\n",
    "        self.class_index = class_index\n",
    "        self.in_channels = in_channels\n",
    "        self.device = device\n",
    "        self.layer0 = nn.Sequential(nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "                                    nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(kernel_size=3, stride=2, padding=1))\n",
    "        self.layer1 = self.create_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.create_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.create_layer(128, 128, stride=1)\n",
    "        self.layer4 = self.create_layer(128, 256, stride=2)\n",
    "        self.layer5 = self.create_layer(256, 256, stride=1)\n",
    "        self.layer6 = self.create_layer(256, 512, stride=2)\n",
    "        self.layer7 = self.create_layer(512, 512, stride=1)\n",
    "        self.layer8 = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.Flatten())\n",
    "        self.layer9 = nn.Sequential(nn.Dropout(0.2),nn.Linear(512, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    #with class Block create layers\n",
    "    def create_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "                                                nn.BatchNorm1d(out_channels))\n",
    "        \n",
    "        return nn.Sequential(to_device(Block(in_channels, out_channels, identity_downsample, stride),\n",
    "                                       self.device),\n",
    "                             to_device(Block(out_channels, out_channels),self.device))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer0(x)\n",
    "  \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        x = self.layer6(x)\n",
    "\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "\n",
    "        x = self.layer9(x)\n",
    "        return x \n",
    "    \n",
    "   \n",
    "    #calculating batch loss\n",
    "    def training_step(self,batch):\n",
    "      signals,targets = batch\n",
    "      preds = self((signals.float())) \n",
    "      loss = nn.BCELoss()\n",
    "      return loss(preds, torch.unsqueeze(targets[:,self.class_index],1).float())\n",
    "    \n",
    "\n",
    "    #making prediction to count metrics\n",
    "    def validation_step(self,batch):\n",
    "      signals,targets = batch\n",
    "      preds = self((signals.float()))\n",
    "      return { 'batch_preds': preds.detach(), 'batch_targets': torch.unsqueeze(targets[:,self.class_index],1).float()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp_phd_sZa27"
   },
   "source": [
    "# 3. Оценивание\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlY1ZXYdmjcv"
   },
   "outputs": [],
   "source": [
    "#calculating metrics of epoch, returning dict of metrics\n",
    "def evaluate(model, valid_dataset,device):\n",
    "  model.eval()\n",
    "  metric_F1 = BinaryF1Score().to(device)\n",
    "  metric_Rec = BinaryRecall().to(device)\n",
    "  metric_Spec = BinarySpecificity().to(device)\n",
    "  metric_AUC = BinaryAUROC(thresholds=None).to(device)\n",
    "  metric_Acc = BinaryAccuracy().to(device)\n",
    "  with torch.no_grad():\n",
    "    for batch in valid_dataset:\n",
    "      tmp = model.validation_step(batch)\n",
    "      metric_F1(tmp['batch_preds'], tmp['batch_targets'] )\n",
    "      metric_Rec(tmp['batch_preds'], tmp['batch_targets'] )\n",
    "      metric_Spec(tmp['batch_preds'], tmp['batch_targets'] )\n",
    "      metric_AUC(tmp['batch_preds'], tmp['batch_targets'] )\n",
    "      metric_Acc(tmp['batch_preds'], tmp['batch_targets'] )\n",
    "\n",
    "\n",
    "  \n",
    "  return {'model_acc': metric_Acc.compute().item(),'model_F1score': metric_F1.compute().item(),'model_Recall': metric_Rec.compute().item(),\n",
    "          'model_Specificity': metric_Spec.compute().item(), 'model_ROCAUC': metric_AUC.compute().item() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2uHJXstfglx"
   },
   "outputs": [],
   "source": [
    "#ploting metrics/epoch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visual_res(history, epoch_num ):\n",
    "  plt.title('Динамика обучения') \n",
    "  plt.xlabel('Эпоха')\n",
    "  plt.ylabel('Метрика')\n",
    "  \n",
    "  \n",
    "  # list_of_metrics содержит наборы значений метрик для построения графика метрика/номер эпохи\n",
    "  plt.plot(list(range(epoch_num)), [x['model_F1score'] for x in history],label = 'F1')\n",
    "  plt.plot(list(range(epoch_num)), [x['model_Recall'] for x in history],label = 'Recall')\n",
    "  plt.plot(list(range(epoch_num)), [x['model_Specificity'] for x in history], label = 'Specificity')\n",
    "  plt.plot(list(range(epoch_num)), [x['model_ROCAUC'] for x in history], label = 'AUC')\n",
    "  plt.plot(list(range(epoch_num)), [x['model_acc'] for x in history], label = 'Acc')\n",
    "  # plt.plot(list(range(epoch_num)), [x['epoch_loss'] for x in history], label = 'loss')\n",
    "  plt.grid(True)\n",
    "  plt.legend()\n",
    "  #построение графиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCmtG8QaRg-6"
   },
   "source": [
    "# 4. Использование GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQkep_1MRlW3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available(): return torch.device('cuda')\n",
    "    else: return torch.device('cpu')\n",
    " \n",
    "def to_device(data, device):\n",
    "  if isinstance(data, (list)): return [to_device(x, device) for x in data]\n",
    "  return data.to(device, non_blocking=True)\n",
    "  \n",
    "#creating generator for batch to gpu\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "        \n",
    "device = get_default_device()\n",
    "train_dataset = DeviceDataLoader(train_dataset, device)\n",
    "valid_dataset = DeviceDataLoader(valid_dataset, device)\n",
    "test_dataset = DeviceDataLoader(test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFAkSs_HRluI"
   },
   "source": [
    "# 5. Функция тренировки модели\n",
    "    Сохраняем метрики и динамику функции потерь для каждой эпохи в переменной history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdbHD-kRSsgP"
   },
   "outputs": [],
   "source": [
    "def fit(epoch_num, lr, model, gc, wd ,opt,device,key):\n",
    "  \n",
    "  patallogies = {0: 'sinus_rhythm', 1: 'atrial_fibrillation',2: 'sinus tachycardia',\n",
    "                 3: 'sinus arrhythmia', 4: 'sinus_bradycardia'}\n",
    "\n",
    "  opt = opt(model.parameters(), lr, weight_decay = wd )\n",
    "  history = []\n",
    "  #for every epoch we will save model in Model.dir\n",
    "  #later we will chose one with better scores\n",
    "  for epoch in range(epoch_num):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    train_losses = 0\n",
    "    for batch in train_dataset:\n",
    "      loss = model.training_step(batch) \n",
    "      train_losses/=2\n",
    "      train_losses+=loss.detach()\n",
    "      loss.backward()\n",
    "      nn.utils.clip_grad_value_(model.parameters(), gc)\n",
    "      opt.step()\n",
    "      opt.zero_grad()\n",
    "      \n",
    "    result = evaluate(model, valid_dataset,device)\n",
    "    history.append(result)\n",
    "\n",
    "    print('Epoch ', epoch,end = \"\")\n",
    "    print(': train_loss = %.4f'%train_losses)\n",
    "\n",
    "    PATH = f'/content/drive/My Drive/ColabNotebooks/ECG/Model1/{patallogies[key]}{epoch}.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "  return history\n",
    "\n",
    "\n",
    "def train_model(res, lr, epochs,  device,key_t, opt_func = torch.optim.Adam):\n",
    "\n",
    "  history = []\n",
    "  model = res\n",
    "  history += fit(epochs, lr, model, gc, wd, opt_func,device,key_t)\n",
    "  visual_res(history,epochs)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S82ShM-btFcw"
   },
   "source": [
    "# 6. Тренировка модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZtNa06qDNGU"
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 1\n",
    "gc = 0.1\n",
    "wd = 0.01\n",
    "pat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTQM8jTvU40G"
   },
   "outputs": [],
   "source": [
    "res = to_device(RhythmECGClassification(12,1,pat,device), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLeXvXzuB-WO"
   },
   "outputs": [],
   "source": [
    "res = train_model(res, lr,epochs,device, pat)\n",
    "eval = evaluate(res, test_dataset,device)\n",
    "for keys in eval:\n",
    "    print(keys, '=' ,eval[keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oXJ3IowZIbX"
   },
   "source": [
    "# 7. Результат. Загрузка модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5pvpj0S1Vqo"
   },
   "outputs": [],
   "source": [
    "general_metrics = {}\n",
    "general_metrics1 = {}\n",
    "patallogies = {0: 'sinus_rhythm', 1: 'atrial_fibrillation',2: 'sinus tachycardia',\n",
    "                 3: 'sinus arrhythmia', 4: 'sinus_bradycardia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3824,
     "status": "ok",
     "timestamp": 1681041484687,
     "user": {
      "displayName": "Назарян Марат Гарникович",
      "userId": "18443528347126523641"
     },
     "user_tz": -180
    },
    "id": "d4L52fHB04Hh",
    "outputId": "a5a35627-b27c-4c39-e3dd-faedf6ac3886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_acc = 0.9708113074302673\n",
      "model_F1score = 0.0\n",
      "model_Recall = 0.0\n",
      "model_Specificity = 1.0\n",
      "model_ROCAUC = 0.6421321630477905\n"
     ]
    }
   ],
   "source": [
    "word = 'sinus_bradycardia1'\n",
    "PATH = f'/content/drive/My Drive/ColabNotebooks/ECG/Model1/{word}.pth'\n",
    "res = to_device(RhythmECGClassification(12,1,4,device), device)\n",
    "res.load_state_dict(torch.load(PATH))\n",
    "# print(the_model)\n",
    "eval = evaluate(res, test_dataset,device)\n",
    "for keys in eval:\n",
    "    print(keys, '=' ,eval[keys])\n",
    "general_metrics[word] = eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1681041515799,
     "user": {
      "displayName": "Назарян Марат Гарникович",
      "userId": "18443528347126523641"
     },
     "user_tz": -180
    },
    "id": "gn4vR2ch08bT",
    "outputId": "e9434141-96f4-4e45-8312-cdc5e6d5b1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sinus_rhythm1': {'model_acc': 0.833371639251709,\n",
       "  'model_F1score': 0.9030100107192993,\n",
       "  'model_Recall': 0.9944018721580505,\n",
       "  'model_Specificity': 0.2622779607772827,\n",
       "  'model_ROCAUC': 0.8836913108825684},\n",
       " 'atrial_fibrillation18': {'model_acc': 0.7692484259605408,\n",
       "  'model_F1score': 0.370138019323349,\n",
       "  'model_Recall': 1.0,\n",
       "  'model_Specificity': 0.7524654865264893,\n",
       "  'model_ROCAUC': 0.9929792284965515},\n",
       " 'sinus tachycardia4': {'model_acc': 0.9820730686187744,\n",
       "  'model_F1score': 0.7845304012298584,\n",
       "  'model_Recall': 0.9161290526390076,\n",
       "  'model_Specificity': 0.9845090508460999,\n",
       "  'model_ROCAUC': 0.9910898208618164},\n",
       " 'sinus arrhythmia5': {'model_acc': 0.9680533409118652,\n",
       "  'model_F1score': 0.0,\n",
       "  'model_Recall': 0.0,\n",
       "  'model_Specificity': 1.0,\n",
       "  'model_ROCAUC': 0.5116299986839294},\n",
       " 'sinus_bradycardia1': {'model_acc': 0.9708113074302673,\n",
       "  'model_F1score': 0.0,\n",
       "  'model_Recall': 0.0,\n",
       "  'model_Specificity': 1.0,\n",
       "  'model_ROCAUC': 0.6421321630477905}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjMT9Afig8L0"
   },
   "source": [
    "# Тесты и итоговые метрики"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EUztugyozL1s",
    "oWZc0f7GzTOR",
    "-Q4-_nzG9WJd",
    "u6cTmywuKyUT",
    "vp_phd_sZa27",
    "TCmtG8QaRg-6",
    "YFAkSs_HRluI"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
