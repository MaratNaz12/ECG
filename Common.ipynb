{"cells":[{"cell_type":"markdown","metadata":{"id":"pgYdY0rUerwu"},"source":["# 0. Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrd2CixBbopP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3b350e2-a269-42a4-95d0-0397608f21a7","executionInfo":{"status":"ok","timestamp":1681039499925,"user_tz":-180,"elapsed":53911,"user":{"displayName":"Назарян Марат Гарникович","userId":"18443528347126523641"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wfdb\n","  Downloading wfdb-4.1.0-py3-none-any.whl (159 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from wfdb) (3.7.1)\n","Collecting SoundFile<0.12.0,>=0.10.0\n","  Downloading soundfile-0.11.0-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (2.27.1)\n","Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.4.4)\n","Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.10.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.22.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (4.39.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (23.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.2.2->wfdb) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.2->wfdb) (1.16.0)\n","Installing collected packages: SoundFile, wfdb\n","  Attempting uninstall: SoundFile\n","    Found existing installation: soundfile 0.12.1\n","    Uninstalling soundfile-0.12.1:\n","      Successfully uninstalled soundfile-0.12.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed SoundFile-0.11.0 wfdb-4.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.10.7)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting neurokit2\n","  Downloading neurokit2-0.2.4-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from neurokit2) (1.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from neurokit2) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from neurokit2) (3.7.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neurokit2) (1.4.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from neurokit2) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.1.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (1.0.7)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->neurokit2) (4.39.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neurokit2) (2022.7.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->neurokit2) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\n","Installing collected packages: neurokit2\n","Successfully installed neurokit2-0.2.4\n","Mounted at /content/drive/\n"]}],"source":["!pip install wfdb\n","!pip install torchmetrics\n","!pip install neurokit2\n","import pandas as pd\n","import numpy as np\n","import wfdb\n","import ast\n","import neurokit2 as nk\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import zipfile\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","\n","import csv\n","\n","from torch.utils.data import Dataset\n","from torchmetrics.classification import BinaryF1Score\n","from torchmetrics.classification import BinaryRecall\n","from torchmetrics.classification import BinarySpecificity\n","from torchmetrics.classification import BinaryAUROC\n","from torchmetrics.classification import BinaryAccuracy"]},{"cell_type":"markdown","metadata":{"id":"R-Af7XqVcekW"},"source":["\n","# 1. Подготовка Dataset\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3sVH9yAFM0ae"},"source":["# Dataset class creation"]},{"cell_type":"markdown","source":["## Loading files to VE"],"metadata":{"id":"EUztugyozL1s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iez9hYPFjWJF"},"outputs":[],"source":["#loading files to virtual environment\n","zipf= '/content/drive/My Drive/ColabNotebooks/ECG/ECG.zip'\n","z = zipfile.ZipFile(zipf, 'r')\n","z.extractall()"]},{"cell_type":"markdown","source":["## Dataset class defenition\n","\n"],"metadata":{"id":"oWZc0f7GzTOR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bo5QcMZjM4hp"},"outputs":[],"source":["class DatasetPTBXL(Dataset):\n","  def __init__(self, path = r\"/content/ECG/\", sampling_rate = 100):\n","\n","    \n","    #list of rhythm patallogies\n","    agg_df = pd.read_csv(path+ r'scp_statements.csv', index_col=0)\n","    self.target_list  = list(agg_df[agg_df.rhythm == 1].index)\n","\n","    #tensor of pqrst features of ECG\n","    # self.pqrst = torch.tensor(np.array(pd.read_csv(path+r'ECG_PQRST_Features.txt', sep=',', header=None)))\n","\n","    #list of indexes of ECG, which neurokit didn't manage to analyze\n","    self.exceptions = pd.read_csv(path+r'exc.txt', sep=',', header=None).values[0]\n","\n","    #extracting features and targets\n","    Y = pd.read_csv(path+r'ptbxl_database.csv', index_col='ecg_id')\n","    Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x)) \n","\n","    self.data = self.load_raw_data(Y, sampling_rate,path)\n","    Y = Y.scp_codes.apply(self.aggregate_diagnostic)\n","\n","    #deleting exceptions \n","    for index in self.exceptions:\n","      del Y[index]\n","    self.targets = torch.tensor(np.array(list(Y)))\n","\n","\n","    #Success\n","    self.show()\n","    \n","\n","  def __len__(self):\n","    return self.data.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return (self.data[idx],  self.targets[idx])\n","\n","  #helping funcs\n","\n","  #creating vector of targets from dicts\n","  # {'IMI': 35.0, 'ABQRS': 0.0, 'SR': 0.0} ---> [1 0 0 0 0 0 0 0 0 0 0 0] \n","  def aggregate_diagnostic(self, y_dic):\n","      tmp = [0] * (len(self.target_list))\n","      for i in range (len(self.target_list)):\n","          if self.target_list[i] in y_dic:\n","              tmp[i] = 1\n","      return tmp\n","\n","\n","\n","  #extracting ECG tesnors\n","  def load_raw_data(self, df, sampling_rate, path):\n","      data = []\n","      c=0\n","      #for every file\n","      for f in getattr(df, self.dir_name(sampling_rate)):\n","        if not (c in self.exceptions): \n","          if c%2170 == 0: print(c/217,'%',end = ' ')\n","          tmp,_ = wfdb.rdsamp(path+f)\n","          tmp = np.array(tmp).T\n","          data.append(tmp)\n","        c+=1\n","      data = torch.tensor(np.array(data))\n","     \n","      return data\n","\n","\n","  # working with certain files type\n","  def dir_name (self, sampling_rate):\n","    if sampling_rate == 100: return 'filename_lr'\n","    else:                    return 'filename_hr'\n","\n"," \n","  #success\n","  def show(self):\n","    print(\"Информация успешно загружена и обработана\\n\",\n","          \"Набор ЭКГ:\\n\",self.data.size(),\n","          \"\\nНабор таргетов:\\n\", self.targets.size(),\n","          \"\\nМножество классов:\\n\",self.target_list)\n","\n","\n","  "]},{"cell_type":"markdown","metadata":{"id":"-Q4-_nzG9WJd"},"source":["## DataLoad\n","\n","\n","*   Splitting into train/valid/test\n","*   Spliting into batches\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqE4ncf0x-SY","outputId":"4fcf7450-2c46-4bf6-b405-f3d64da14702","executionInfo":{"status":"ok","timestamp":1681039745166,"user_tz":-180,"elapsed":93919,"user":{"displayName":"Назарян Марат Гарникович","userId":"18443528347126523641"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.0 % 10.0 % 20.0 % 30.0 % 40.0 % 50.0 % 60.0 % 70.0 % 80.0 % 90.0 % 100.0 % Информация успешно загружена и обработана\n"," Набор ЭКГ:\n"," torch.Size([21747, 12, 1000]) \n","Набор таргетов:\n"," torch.Size([21747, 12]) \n","Множество классов:\n"," ['SR', 'AFIB', 'STACH', 'SARRH', 'SBRAD', 'PACE', 'SVARR', 'BIGU', 'AFLT', 'SVTAC', 'PSVT', 'TRIGU']\n"]}],"source":["train_dataset = DatasetPTBXL()\n","target_list = train_dataset.target_list\n","train_dataset, valid_dataset,test_dataset = random_split(train_dataset, [int(0.7* len(train_dataset)), int(0.1*len(train_dataset)), \n","                                                                         len(train_dataset) - int(0.7*len(train_dataset))- int(0.1*len(train_dataset))])\n","batch_size = 500\n","train_dataset = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_dataset = DataLoader(valid_dataset, batch_size , num_workers=0, pin_memory=True)\n","test_dataset = DataLoader(test_dataset,batch_size,num_workers =0 , pin_memory = True )\n"]},{"cell_type":"markdown","metadata":{"id":"_uu8Y928Rf3A"},"source":["# 2. CNN model defeniton\n"," \n","\n"]},{"cell_type":"markdown","metadata":{"id":"u6cTmywuKyUT"},"source":["## Model class"]},{"cell_type":"code","source":["\n","#resudial block defenition\n","class Block(nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n","        super(Block, self).__init__()\n","\n","        self.resblock = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n","                      nn.BatchNorm1d(out_channels),\n","                      nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n","                      nn.BatchNorm1d(out_channels))\n","\n","        self.relu = nn.ReLU()\n","        self.identity_downsample = identity_downsample\n","        \n","    def forward(self, x):\n","        identity = x\n","        x = self.resblock(x)\n","        #in case we need to double size of identity\n","        if self.identity_downsample is not None:\n","            identity = self.identity_downsample(identity)\n","        x += identity\n","        x = self.relu(x)\n","        return x"],"metadata":{"id":"OSi9xCepUm1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ResNet34\n","class RhythmECGClassification(nn.Module):\n","    \n","    def __init__(self, in_channels, num_classes,class_index,device):\n","        \n","        super(RhythmECGClassification, self).__init__()\n","        self.class_index = class_index\n","        self.in_channels = in_channels\n","        self.device = device\n","        self.layer0 = nn.Sequential(nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n","                                    nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(kernel_size=3, stride=2, padding=1))\n","        self.layer1 = self.create_layer(64, 64, stride=1)\n","        self.layer2 = self.create_layer(64, 128, stride=2)\n","        self.layer3 = self.create_layer(128, 128, stride=1)\n","        self.layer4 = self.create_layer(128, 256, stride=2)\n","        self.layer5 = self.create_layer(256, 256, stride=1)\n","        self.layer6 = self.create_layer(256, 512, stride=2)\n","        self.layer7 = self.create_layer(512, 512, stride=1)\n","        self.layer8 = nn.Sequential(nn.AdaptiveAvgPool1d(1), nn.Flatten())\n","        self.layer9 = nn.Sequential(nn.Dropout(0.2),nn.Linear(512, num_classes), nn.Sigmoid())\n","        \n","    #with class Block create layers\n","    def create_layer(self, in_channels, out_channels, stride):\n","        \n","        identity_downsample = None\n","        if stride != 1:\n","            identity_downsample = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n","                                                nn.BatchNorm1d(out_channels))\n","        \n","        return nn.Sequential(to_device(Block(in_channels, out_channels, identity_downsample, stride),\n","                                       self.device),\n","                             to_device(Block(out_channels, out_channels),self.device))\n","        \n","        \n","    def forward(self, x):\n","\n","        x = self.layer0(x)\n","  \n","        x = self.layer1(x)\n","        x = self.layer1(x)\n","        x = self.layer1(x)\n","\n","        x = self.layer2(x)\n","\n","        x = self.layer3(x)\n","        x = self.layer3(x)\n","        x = self.layer3(x)\n","\n","        x = self.layer4(x)\n","\n","        x = self.layer5(x)\n","        x = self.layer5(x)\n","        x = self.layer5(x)\n","        x = self.layer5(x)\n","        x = self.layer5(x)\n","\n","        x = self.layer6(x)\n","\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","\n","        x = self.layer9(x)\n","        return x \n","    \n","   \n","    #calculating batch loss\n","    def training_step(self,batch):\n","      signals,targets = batch\n","      preds = self((signals.float())) \n","      loss = nn.BCELoss()\n","      return loss(preds, torch.unsqueeze(targets[:,self.class_index],1).float())\n","    \n","\n","    #making prediction to count metrics\n","    def validation_step(self,batch):\n","      signals,targets = batch\n","      preds = self((signals.float()))\n","      return { 'batch_preds': preds.detach(), 'batch_targets': torch.unsqueeze(targets[:,self.class_index],1).float()}"],"metadata":{"id":"YWShc0EwYxYj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vp_phd_sZa27"},"source":["# 3. Оценивание\n","    \n","    \n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlY1ZXYdmjcv"},"outputs":[],"source":["#calculating metrics of epoch, returning dict of metrics\n","def evaluate(model, valid_dataset,device):\n","  model.eval()\n","  metric_F1 = BinaryF1Score().to(device)\n","  metric_Rec = BinaryRecall().to(device)\n","  metric_Spec = BinarySpecificity().to(device)\n","  metric_AUC = BinaryAUROC(thresholds=None).to(device)\n","  metric_Acc = BinaryAccuracy().to(device)\n","  with torch.no_grad():\n","    for batch in valid_dataset:\n","      tmp = model.validation_step(batch)\n","      metric_F1(tmp['batch_preds'], tmp['batch_targets'] )\n","      metric_Rec(tmp['batch_preds'], tmp['batch_targets'] )\n","      metric_Spec(tmp['batch_preds'], tmp['batch_targets'] )\n","      metric_AUC(tmp['batch_preds'], tmp['batch_targets'] )\n","      metric_Acc(tmp['batch_preds'], tmp['batch_targets'] )\n","\n","\n","  \n","  return {'model_acc': metric_Acc.compute().item(),'model_F1score': metric_F1.compute().item(),'model_Recall': metric_Rec.compute().item(),\n","          'model_Specificity': metric_Spec.compute().item(), 'model_ROCAUC': metric_AUC.compute().item() }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I2uHJXstfglx"},"outputs":[],"source":["#ploting metrics/epoch\n","import matplotlib.pyplot as plt\n","\n","def visual_res(history, epoch_num ):\n","  plt.title('Динамика обучения') \n","  plt.xlabel('Эпоха')\n","  plt.ylabel('Метрика')\n","  \n","  \n","  # list_of_metrics содержит наборы значений метрик для построения графика метрика/номер эпохи\n","  plt.plot(list(range(epoch_num)), [x['model_F1score'] for x in history],label = 'F1')\n","  plt.plot(list(range(epoch_num)), [x['model_Recall'] for x in history],label = 'Recall')\n","  plt.plot(list(range(epoch_num)), [x['model_Specificity'] for x in history], label = 'Specificity')\n","  plt.plot(list(range(epoch_num)), [x['model_ROCAUC'] for x in history], label = 'AUC')\n","  plt.plot(list(range(epoch_num)), [x['model_acc'] for x in history], label = 'Acc')\n","  # plt.plot(list(range(epoch_num)), [x['epoch_loss'] for x in history], label = 'loss')\n","  plt.grid(True)\n","  plt.legend()\n","  #построение графиков"]},{"cell_type":"markdown","metadata":{"id":"TCmtG8QaRg-6"},"source":["# 4. Использование GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQkep_1MRlW3"},"outputs":[],"source":["\n","def get_default_device():\n","    if torch.cuda.is_available(): return torch.device('cuda')\n","    else: return torch.device('cpu')\n"," \n","def to_device(data, device):\n","  if isinstance(data, (list)): return [to_device(x, device) for x in data]\n","  return data.to(device, non_blocking=True)\n","  \n","#creating generator for batch to gpu\n","class DeviceDataLoader():\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        return len(self.dl)\n","        \n","device = get_default_device()\n","train_dataset = DeviceDataLoader(train_dataset, device)\n","valid_dataset = DeviceDataLoader(valid_dataset, device)\n","test_dataset = DeviceDataLoader(test_dataset, device)"]},{"cell_type":"markdown","metadata":{"id":"YFAkSs_HRluI"},"source":["# 5. Функция тренировки модели\n","    Сохраняем метрики и динамику функции потерь для каждой эпохи в переменной history.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdbHD-kRSsgP"},"outputs":[],"source":["def fit(epoch_num, lr, model, gc, wd ,opt,device,key):\n","  \n","  patallogies = {0: 'sinus_rhythm', 1: 'atrial_fibrillation',2: 'sinus tachycardia',\n","                 3: 'sinus arrhythmia', 4: 'sinus_bradycardia'}\n","\n","  opt = opt(model.parameters(), lr, weight_decay = wd )\n","  history = []\n","  #for every epoch we will save model in Model.dir\n","  #later we will chose one with better scores\n","  for epoch in range(epoch_num):\n","    torch.cuda.empty_cache()\n","    model.train()\n","    train_losses = 0\n","    for batch in train_dataset:\n","      loss = model.training_step(batch) \n","      train_losses/=2\n","      train_losses+=loss.detach()\n","      loss.backward()\n","      nn.utils.clip_grad_value_(model.parameters(), gc)\n","      opt.step()\n","      opt.zero_grad()\n","      \n","    result = evaluate(model, valid_dataset,device)\n","    history.append(result)\n","\n","    print('Epoch ', epoch,end = \"\")\n","    print(': train_loss = %.4f'%train_losses)\n","\n","    PATH = f'/content/drive/My Drive/ColabNotebooks/ECG/Model1/{patallogies[key]}{epoch}.pth'\n","    torch.save(model.state_dict(), PATH)\n","  return history\n","\n","\n","def train_model(res, lr, epochs,  device,key_t, opt_func = torch.optim.Adam):\n","\n","  history = []\n","  model = res\n","  history += fit(epochs, lr, model, gc, wd, opt_func,device,key_t)\n","  visual_res(history,epochs)\n","  \n","  return model"]},{"cell_type":"markdown","metadata":{"id":"S82ShM-btFcw"},"source":["# 6. Тренировка модели\n"]},{"cell_type":"code","source":["lr = 0.1\n","epochs = 1\n","gc = 0.1\n","wd = 0.01\n","pat = 3"],"metadata":{"id":"QZtNa06qDNGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = to_device(RhythmECGClassification(12,1,pat,device), device)"],"metadata":{"id":"KTQM8jTvU40G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res = train_model(res, lr,epochs,device, pat)\n","eval = evaluate(res, test_dataset,device)\n","for keys in eval:\n","    print(keys, '=' ,eval[keys])"],"metadata":{"id":"FLeXvXzuB-WO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5oXJ3IowZIbX"},"source":["# 7. Результат. Загрузка модели."]},{"cell_type":"code","source":["general_metrics = {}\n","general_metrics1 = {}\n","patallogies = {0: 'sinus_rhythm', 1: 'atrial_fibrillation',2: 'sinus tachycardia',\n","                 3: 'sinus arrhythmia', 4: 'sinus_bradycardia'}"],"metadata":{"id":"k5pvpj0S1Vqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word = 'sinus_bradycardia1'\n","PATH = f'/content/drive/My Drive/ColabNotebooks/ECG/Model1/{word}.pth'\n","res = to_device(RhythmECGClassification(12,1,4,device), device)\n","res.load_state_dict(torch.load(PATH))\n","# print(the_model)\n","eval = evaluate(res, test_dataset,device)\n","for keys in eval:\n","    print(keys, '=' ,eval[keys])\n","general_metrics[word] = eval\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4L52fHB04Hh","executionInfo":{"status":"ok","timestamp":1681041484687,"user_tz":-180,"elapsed":3824,"user":{"displayName":"Назарян Марат Гарникович","userId":"18443528347126523641"}},"outputId":"a5a35627-b27c-4c39-e3dd-faedf6ac3886"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_acc = 0.9708113074302673\n","model_F1score = 0.0\n","model_Recall = 0.0\n","model_Specificity = 1.0\n","model_ROCAUC = 0.6421321630477905\n"]}]},{"cell_type":"code","source":["general_metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gn4vR2ch08bT","executionInfo":{"status":"ok","timestamp":1681041515799,"user_tz":-180,"elapsed":226,"user":{"displayName":"Назарян Марат Гарникович","userId":"18443528347126523641"}},"outputId":"e9434141-96f4-4e45-8312-cdc5e6d5b1a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'sinus_rhythm1': {'model_acc': 0.833371639251709,\n","  'model_F1score': 0.9030100107192993,\n","  'model_Recall': 0.9944018721580505,\n","  'model_Specificity': 0.2622779607772827,\n","  'model_ROCAUC': 0.8836913108825684},\n"," 'atrial_fibrillation18': {'model_acc': 0.7692484259605408,\n","  'model_F1score': 0.370138019323349,\n","  'model_Recall': 1.0,\n","  'model_Specificity': 0.7524654865264893,\n","  'model_ROCAUC': 0.9929792284965515},\n"," 'sinus tachycardia4': {'model_acc': 0.9820730686187744,\n","  'model_F1score': 0.7845304012298584,\n","  'model_Recall': 0.9161290526390076,\n","  'model_Specificity': 0.9845090508460999,\n","  'model_ROCAUC': 0.9910898208618164},\n"," 'sinus arrhythmia5': {'model_acc': 0.9680533409118652,\n","  'model_F1score': 0.0,\n","  'model_Recall': 0.0,\n","  'model_Specificity': 1.0,\n","  'model_ROCAUC': 0.5116299986839294},\n"," 'sinus_bradycardia1': {'model_acc': 0.9708113074302673,\n","  'model_F1score': 0.0,\n","  'model_Recall': 0.0,\n","  'model_Specificity': 1.0,\n","  'model_ROCAUC': 0.6421321630477905}}"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# Тесты и итоговые метрики"],"metadata":{"id":"YjMT9Afig8L0"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["EUztugyozL1s","oWZc0f7GzTOR","-Q4-_nzG9WJd","u6cTmywuKyUT","vp_phd_sZa27","TCmtG8QaRg-6","YFAkSs_HRluI"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}